{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTIVITIES DATA TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent sources:\n",
      "Series([], Name: sourceID, dtype: int64)\n",
      "\n",
      "Inconsistent IDs:\n",
      "Series([], Name: source, dtype: int64)\n",
      "\n",
      "Invalid characters:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Tables/Activities.csv')\n",
    "\n",
    "#Checks if each source matches to a single ID\n",
    "source_to_sourceID = data.groupby('source')['sourceID'].nunique()\n",
    "inconsistent_sources = source_to_sourceID[source_to_sourceID > 1]\n",
    "\n",
    "#Checks the other way around\n",
    "sourceID_to_source = data.groupby('sourceID')['source'].nunique()\n",
    "inconsistent_sourceIDs = sourceID_to_source[sourceID_to_source > 1]\n",
    "\n",
    "#Checks alphabet encoding errors\n",
    "unique_sources = data['source'].unique()\n",
    "encoding_issues = [s for s in unique_sources if not s.isascii()]\n",
    "\n",
    "\n",
    "print(\"Inconsistent sources:\")\n",
    "print(inconsistent_sources)\n",
    "\n",
    "print(\"\\nInconsistent IDs:\")\n",
    "print(inconsistent_sourceIDs)\n",
    "\n",
    "print(\"\\nInvalid characters:\")\n",
    "print(encoding_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BILLIONAIRES DATA TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character inconsistencies\n",
      "last_name: ['Saadé', 'Saadé Zeenny', 'Bolloré', 'Seràgnoli', 'Piñera', 'Péladeau', 'Lê-Quôc', 'Österberg', 'Lindén Urnes', 'Käärmann', 'Laliberté', 'Lao Hernández', 'Hagströmer', 'Montipò']\n",
      "first_name: ['François', 'Germán', 'Marie-Hélène', 'Stéphane', 'Réal']\n",
      "industry: No encoding errors found\n",
      "\n",
      "Character inconsistencies\n",
      "last_name: No encoding errors found\n",
      "first_name: No encoding errors found\n",
      "industry: No encoding errors found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1930-08-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   birth_date\n",
       "0  1949-03-05\n",
       "1  1971-06-28\n",
       "2  1964-01-12\n",
       "3  1944-08-17\n",
       "4  1930-08-30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "data = pd.read_csv('Tables/Billionaires.csv')\n",
    "\n",
    "text_columns = [\"last_name\",\"first_name\",\"industry\"]\n",
    "\n",
    "#checks for invalid characters in each collumn in the list\n",
    "invalid_characters = {}\n",
    "for col in text_columns:\n",
    "    unique_values = data[col].unique()\n",
    "    invalid_values = [val for val in unique_values if not isinstance(val, str) or not val.isascii()]\n",
    "    invalid_characters[col] = invalid_values\n",
    "\n",
    "#prints inconsistencies found\n",
    "print(\"\\nCharacter inconsistencies\")\n",
    "for col, issues in invalid_characters.items():\n",
    "    if issues:\n",
    "        print(f\"{col}: {issues}\")\n",
    "    else:\n",
    "        print(f\"{col}: No encoding errors found\")\n",
    "\n",
    "#replaces invalid characters to their closest ASCII equivalent\n",
    "def replace_invalid_chars(value):\n",
    "    if isinstance(value, str):\n",
    "        return unidecode(value)\n",
    "    return value\n",
    "\n",
    "#applies the above function\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].apply(replace_invalid_chars)\n",
    "\n",
    "#check for iunvalid characters again\n",
    "#checks for invalid characters in each collumn in the list\n",
    "invalid_characters = {}\n",
    "for col in text_columns:\n",
    "    unique_values = data[col].unique()\n",
    "    invalid_values = [val for val in unique_values if not isinstance(val, str) or not val.isascii()]\n",
    "    invalid_characters[col] = invalid_values\n",
    "\n",
    "#prints inconsistencies found\n",
    "print(\"\\nCharacter inconsistencies\")\n",
    "for col, issues in invalid_characters.items():\n",
    "    if issues:\n",
    "        print(f\"{col}: {issues}\")\n",
    "    else:\n",
    "        print(f\"{col}: No encoding errors found\")\n",
    "#end of second check\n",
    "\n",
    "# Converts 'birth_date' from MM/DD/YYYY to YYYY-MM-DD format\n",
    "data['birth_date'] = pd.to_datetime(data['birth_date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#preview\n",
    "data[['birth_date']].head()\n",
    "\n",
    "#modifies the actual .csv file\n",
    "#data.to_csv('Tables/Billionaires.csv', index=False)\n",
    "\n",
    "#print(\"updated csv file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CITIES DATA TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid characters found in name\n",
      "[]\n",
      "\n",
      "CityIDs with more than 1 name\n",
      "Series([], Name: name, dtype: int64)\n",
      "\n",
      "Names with more than 1 CityID\n",
      "Series([], Name: cityID, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "data = pd.read_csv('Tables/Cities.csv')\n",
    "\n",
    "#check for invalid characters in \"name\"\n",
    "invalid_characters_in_name = [\n",
    "    name for name in data['name'].unique() \n",
    "    if not isinstance(name, str) or name != unidecode(name)\n",
    "]\n",
    "\n",
    "print(\"invalid characters found in name\")\n",
    "print(invalid_characters_in_name)\n",
    "\n",
    "#checks if each cityID and city name is unique\n",
    "cityID_to_name = data.groupby('cityID')['name'].nunique()\n",
    "name_to_cityID = data.groupby('name')['cityID'].nunique()\n",
    "\n",
    "#checks if there are non unique ids and names\n",
    "cityID_issues = cityID_to_name[cityID_to_name > 1]\n",
    "name_issues = name_to_cityID[name_to_cityID > 1]\n",
    "\n",
    "print(\"\\nCityIDs with more than 1 name\")\n",
    "print(cityID_issues)\n",
    "\n",
    "print(\"\\nNames with more than 1 CityID\")\n",
    "print(name_issues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNTRIES DATA TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid characters\n",
      "name: []\n",
      "continent: []\n",
      "\n",
      "duplicate names found\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "data = pd.read_csv('Tables/Countries.csv')\n",
    "\n",
    "text_columns = ['name', 'continent']\n",
    "\n",
    "#check for invalid characters\n",
    "invalid_characters = {}\n",
    "for col in text_columns:\n",
    "    invalid_characters[col] = [\n",
    "        value for value in data[col].unique()\n",
    "        if not isinstance(value, str) or value != unidecode(value)\n",
    "    ]\n",
    "\n",
    "print(\"invalid characters\")\n",
    "for col, issues in invalid_characters.items():\n",
    "    print(f\"{col}: {issues}\")\n",
    "\n",
    "#checks if names are repeated\n",
    "duplicate_names = data['name'][data['name'].duplicated()]\n",
    "print(\"\\nduplicate names found\")\n",
    "print(duplicate_names.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCES OF WEALTH TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid characters:\n",
      "source: []\n",
      "\n",
      "Duplicate sources found:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "data = pd.read_csv('Tables/SourcesOfWealth.csv')\n",
    "\n",
    "invalid_characters = {}\n",
    "\n",
    "#check invalid characters in source\n",
    "invalid_characters['source'] = [\n",
    "    value for value in data['source'].unique()\n",
    "    if not isinstance(value, str) or value != unidecode(value)\n",
    "]\n",
    "\n",
    "print(\"Invalid characters:\")\n",
    "for col, issues in invalid_characters.items():\n",
    "    print(f\"{col}: {issues}\")\n",
    "\n",
    "#verifies if each source is unique\n",
    "duplicate_sources = data['source'][data['source'].duplicated()]\n",
    "print(\"\\nDuplicate sources found:\")\n",
    "print(duplicate_sources.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US CITIES TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic Cities:\n",
      "     cityID  stateID\n",
      "204     657        7\n",
      "248     657       26\n",
      "249     657       42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('TablePopulation/BackUps/USCities.csv')\n",
    "\n",
    "#check cities with more than one state\n",
    "city_state_counts = data.groupby('cityID')['stateID'].nunique()\n",
    "cities_with_multiple_states = city_state_counts[city_state_counts > 1]\n",
    "\n",
    "# Extract problematic entries\n",
    "problematic_cities = data[data['cityID'].isin(cities_with_multiple_states.index)].sort_values(by=['cityID'])\n",
    "\n",
    "# Display results\n",
    "print(\"Problematic Cities:\")\n",
    "print(problematic_cities)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
